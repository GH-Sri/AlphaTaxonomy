download.file(
url = "https://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download",
destfile =  "companylist.csv")
list.files()
companies <- read.csv("companylist.csv ",stringsAsFactors = FALSE)
View(companies)
companies <- read.csv("companylist.csv ",stringsAsFactors = FALSE)[,c("Symbol","Name")]
View(companies)
sapply(companies,class)
setwd("..")
# Read the local copy of the companylist OR get it from Nasdaq  ----
if(("companylist.xlsx" %in% list.files())){
companies <- read_xlsx("companylist.xlsx")
# if not available read from the Nasdaq site
} else if( !("companylist.xlsx" %in% list.files()) ) {
message("companylist.xlsx is not in this directory, downloading from Nasdaq site")
download.file(
url = "https://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download",
destfile =  "companylist.csv")
companies <- read.csv("companylist.csv ",stringsAsFactors = FALSE)[,c("Symbol","Name")]
}
#----
# Read the local copy of the companylist OR get it from Nasdaq  ----
if(("companylist.xlsx" %in% list.files())){
companies <- read_xlsx("companylist.xlsx")
# if not available read from the Nasdaq site
} else if( !("companylist.xlsx" %in% list.files()) ) {
message("companylist.xlsx is not in this directory, downloading from Nasdaq site")
download.file(
url = "https://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download",
destfile =  "companylist.csv")
companies <- read.csv("companylist.csv ",stringsAsFactors = FALSE)[,c("Symbol","Name")]
}
#----
# Updates the Wikipedia Object Fully
#' these files are ALL EXCHANGES website scrape  but ONLY NASDAQ WIKI
files <- c("./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_1.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_2.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_3.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_4.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_5.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_6.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_7.csv")
source("./file_combine.R") #MDAS - TECH parent directory
source("Wikipedia_Read/Wiki Functions/wiki_db_creator.R")
source("Wikipedia_Read/Wiki Functions/name_clean.R")
source("Wikipedia_Read/Wiki Functions/match_names.R")
source("Wikipedia_Read/Wiki Functions/multi_match_fix.R")
source("Wikipedia_Read/Wiki Functions/combine.R")
setwd("~/MDAS - TECH")
setwd("~/MDAS - TECH")
#' these files are ALL EXCHANGES website scrape  but ONLY NASDAQ WIKI
files <- c("./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_1.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_2.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_3.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_4.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_5.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_6.csv",
"./Results_of_Wiki_Web_Pipeline_Scripts/public_data_for_doc2vec_7.csv")
source("./file_combine.R") #MDAS - TECH parent directory
source("Wikipedia_Read/Wiki Functions/wiki_db_creator.R")
source("Wikipedia_Read/Wiki Functions/name_clean.R")
source("Wikipedia_Read/Wiki Functions/match_names.R")
source("Wikipedia_Read/Wiki Functions/multi_match_fix.R")
source("Wikipedia_Read/Wiki Functions/combine.R")
combined_files <- file_combine(files)
companies <- combined_files[,c("Symbol","Name")]
website_data <-  combined_files[,c("Symbol","Name","finance_site",
"website","description", "keywords")]
website_data$ticker <- website_data$Symbol # legacy col names
new_wiki_data <- wiki_db_creator("./Wikipedia_Read/Wikipedia_Data.json")
matched <- match_names(wiki_names = new_wiki_data$name,
db_names = companies$Name)[,c("wiki_company","companylist_name")]
wiki_complete <- merge(new_wiki_data,matched,by.x = "name",by.y = "wiki_company")
wiki_relevant <- wiki_complete[wiki_complete$companylist_name != "",]
m1 <- merge(companies,wiki_relevant,by.x = "Name",by.y = "companylist_name")
View(m1)
m1 <- merge(companies,wiki_relevant,by.x = "Name",by.y = "companylist_name",all.x = TRUE)
m1 <- merge(companies,wiki_relevant,by.x = "Name",by.y = "companylist_name")
m1 <- merge(companies,wiki_relevant,by.x = "Name",by.y = "companylist_name",all.x = TRUE, all.y = TRUE)
View(m1)
m1$Name[1]
View(m1$Name)
View(m1[m1$Name != ""])
View(m1[m1$Name != "",])
View(combined_files)
m1 <- m1[m1$Name != ""] # ugly subset sorry
m1 <- m1[m1$Name != "",] # ugly subset sorry
r <- merge(m1, website_data,by.x = "Symbol",by.y = "ticker", all.x = TRUE)
View(r)
r <- merge(m1, website_data, all.x = TRUE)
View(r)
